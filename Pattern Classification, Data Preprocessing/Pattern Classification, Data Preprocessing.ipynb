{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc95304e-8754-4f81-bf43-b1fe77565e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "\n",
    "filename = 'Ex_PC_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470924c5-af60-4aec-83ed-b779e145402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      nan 1.710e+00 2.430e+00 ... 3.920e+00 1.065e+03 1.000e+00]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 3.400e+00 1.050e+03 1.000e+00]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 3.170e+00 1.185e+03 1.000e+00]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 1.560e+00 8.350e+02 3.000e+00]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 1.620e+00 8.400e+02 3.000e+00]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 1.600e+00 5.600e+02 3.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (a)\n",
    "\n",
    "# Reading the data file and converting it into a matrix.\n",
    "data = np.genfromtxt(filename, delimiter=',')\n",
    "print(data)\n",
    "\n",
    "\n",
    "# Since we're given that the last column is labels\n",
    "features, labels = data[:, :-1], data[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be08c2b-ffd5-482f-be6c-714526a51a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples = 178\n",
      "Number of features = 13\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (b)\n",
    "\n",
    "# Number of samples and features\n",
    "n_samples, n_features = features.shape\n",
    "\n",
    "print(f'Number of samples = {n_samples}')\n",
    "print(f'Number of features = {n_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd75e6d-e71c-45b5-9e26-a98e9515aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes = 3\n",
      "The classes are: 1, 2, 3\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (b) continued\n",
    "\n",
    "classes = np.unique(labels)\n",
    "n_classes = classes.shape[0]\n",
    "\n",
    "print(f'Number of classes = {n_classes}')\n",
    "print(f'The classes are:', ', '.join(map(str, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "183b6f3a-1060-49e6-8682-32eac38c1958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for label 1 = 0.33146\n",
      "Class distribution for label 2 = 0.39888\n",
      "Class distribution for label 3 = 0.26966\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (b) continued\n",
    "\n",
    "for i in classes:\n",
    "    # Number of labels with class i\n",
    "    count = np.sum(labels == i)\n",
    "    \n",
    "    # pdf of that class\n",
    "    pdf = count / n_samples\n",
    "    \n",
    "    # rounded to 5 decimal places\n",
    "    print(f'Class distribution for label {i} = {pdf:.5}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ba6634-7d7b-4c8f-bb8b-d9243bd3dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Vector for the features = \n",
      "[1.29936723e+01 2.33634831e+00 2.36651685e+00 1.95062500e+01\n",
      " 9.97415730e+01 2.29511236e+00 2.03757062e+00 3.61073446e-01\n",
      " 1.59536723e+00 5.05808989e+00 9.57471910e-01 2.61168539e+00\n",
      " 7.46893258e+02]\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (c)\n",
    "\n",
    "# To impute, we need to first calculate the means of the features\n",
    "feature_means = np.nanmean(features, axis=0)\n",
    "print(f'Mean Vector for the features = \\n{feature_means}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560c7bd6-3c98-46d2-a307-269f83633f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.29936723e+01 1.71000000e+00 2.43000000e+00 ... 1.04000000e+00\n",
      "  3.92000000e+00 1.06500000e+03]\n",
      " [1.32000000e+01 1.78000000e+00 2.14000000e+00 ... 1.05000000e+00\n",
      "  3.40000000e+00 1.05000000e+03]\n",
      " [1.31600000e+01 2.36000000e+00 2.67000000e+00 ... 1.03000000e+00\n",
      "  3.17000000e+00 1.18500000e+03]\n",
      " ...\n",
      " [1.32700000e+01 4.28000000e+00 2.26000000e+00 ... 5.90000000e-01\n",
      "  1.56000000e+00 8.35000000e+02]\n",
      " [1.31700000e+01 2.59000000e+00 2.37000000e+00 ... 6.00000000e-01\n",
      "  1.62000000e+00 8.40000000e+02]\n",
      " [1.41300000e+01 4.10000000e+00 2.74000000e+00 ... 6.10000000e-01\n",
      "  1.60000000e+00 5.60000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (c) continued\n",
    "\n",
    "# Imputing nan values,\n",
    "for i, m in enumerate(feature_means):\n",
    "    # determining where the nan's are in each column\n",
    "    nans = np.where(np.isnan(features[:,i]))[0]\n",
    "    for j in nans:\n",
    "        features[j, i] = m\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715d3c4d-38ab-4248-a94a-cbccd24fc108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset's features = (142, 13)\n",
      "Shape of training dataset's labels   = (142,)\n",
      "Shape of testing dataset's features  = (36, 13)\n",
      "Shape of testing dataset's labels    = (36,)\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (d)\n",
    "\n",
    "ratio = 0.8 # 80 / 20 split\n",
    "\n",
    "# Number of elements in the training set\n",
    "length = int(features.shape[0] * ratio)\n",
    "\n",
    "# get a random permutation of the indices.\n",
    "indices = np.random.permutation(features.shape[0])\n",
    "\n",
    "train_features = features[indices[:length]]\n",
    "train_labels   = labels[indices[:length]]\n",
    "test_features  = features[indices[length:]]\n",
    "test_labels    = labels[indices[length:]]\n",
    "\n",
    "print(\"Shape of training dataset's features =\", train_features.shape)\n",
    "print(\"Shape of training dataset's labels   =\", train_labels.shape)\n",
    "print(\"Shape of testing dataset's features  =\", test_features.shape)\n",
    "print(\"Shape of testing dataset's labels    =\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aaebcf8-209c-445c-b75a-ad4289973f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.439e+01 5.800e+00 3.230e+00 3.000e+01 1.620e+02 3.880e+00 5.080e+00\n",
      " 6.600e-01 3.580e+00 1.300e+01 1.710e+00 4.000e+00 1.680e+03]\n",
      "[1.103e+01 7.400e-01 1.360e+00 1.060e+01 7.000e+01 9.800e-01 3.400e-01\n",
      " 1.300e-01 4.100e-01 1.280e+00 4.800e-01 1.270e+00 2.780e+02]\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (e)\n",
    "\n",
    "max_vector = np.max(train_features, axis=0)\n",
    "min_vector = np.min(train_features, axis=0)\n",
    "print(max_vector)\n",
    "print(min_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35e7f832-c143-4c41-9000-3cd59908aedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max in scaled testing, 6.309523809523808\n",
      "Min in scaled testing, -4.926739926739927\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (e) continued\n",
    "\n",
    "def scale(X: np.ndarray, start: float, end: float) -> np.ndarray:\n",
    "    return (end - start) * (X - min_vector) / (max_vector - min_vector) + start\n",
    "\n",
    "scaled_training_features = scale(train_features, -5, 5)\n",
    "# print(f'scaled_training_features\\n{scaled_training_features}')\n",
    "\n",
    "scaled_testing_features = scale(test_features, -5, 5)\n",
    "# print(f'scaled_testing_features\\n{scaled_testing_features}')\n",
    "\n",
    "print('Max in scaled testing,', np.max(scaled_testing_features))\n",
    "print('Min in scaled testing,', np.min(scaled_testing_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b304e1-2646-44a6-90e0-d3e049b76ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Features mean,  [-0.13751286 -0.22719036  0.20036156  0.13058728 -0.19928962 -0.07675987\n",
      "  0.14512074 -0.13111013  0.08270551 -0.26286111  0.26101634 -0.0426573\n",
      " -0.15247943]\n",
      "Testing Features std,  [0.98297416 0.71760859 0.94781102 1.15158323 0.90993945 0.89348215\n",
      " 0.81246996 0.96095066 0.92824342 0.93399986 1.02408764 0.86194867\n",
      " 0.94288846]\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (f)\n",
    "\n",
    "mean_scaled = np.mean(scaled_training_features, axis=0)\n",
    "std_scaled = np.std(scaled_training_features, axis=0)\n",
    "\n",
    "def normalize(X: np.ndarray) -> np.ndarray:\n",
    "    return (X - mean_scaled) / std_scaled\n",
    "\n",
    "n_s_train = normalize(scaled_training_features)\n",
    "n_s_test = normalize(scaled_testing_features)\n",
    "\n",
    "# print('Scaled and Normalized Training Features,', n_s_train, sep='\\n')\n",
    "# print('Scaled and Normalized Testing Features,', n_s_test, sep='\\n')\n",
    "\n",
    "_mean = np.mean(n_s_test, axis=0)\n",
    "print('Testing Features mean, ', _mean)\n",
    "_std = np.std(n_s_test, axis=0)\n",
    "print('Testing Features std, ', _std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898e6dd4-ea17-4c07-842e-0d46c629e0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution for label 1 = 0.32632\n",
      "Class distribution for label 2 = 0.37895\n",
      "Class distribution for label 3 = 0.29474\n"
     ]
    }
   ],
   "source": [
    "# Question 1 part (g)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(n_s_train):\n",
    "    X_train = n_s_train[train_index]\n",
    "    y_train = train_labels[train_index]\n",
    "\n",
    "for i in classes:\n",
    "    # Number of labels with class i\n",
    "    count = np.sum(y_train == i)\n",
    "    \n",
    "    # pdf of that class\n",
    "    pdf = count / y_train.shape[0]\n",
    "    \n",
    "    # rounded to 5 decimal places\n",
    "    print(f'Class distribution for label {i} = {pdf:.5}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
