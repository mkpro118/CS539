{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da743a4-8239-42d9-bbf8-175307f80252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "\n",
    "# Setup\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32e66ae-92b3-4760-83f6-79da29ca4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply linear regression\n",
    "\n",
    "class LinearRegression:\n",
    "    @staticmethod\n",
    "    def apply(X: np.ndarray, w: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Apply Linear Regression\n",
    "        '''\n",
    "        return (X @ w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3781a9bd-fa30-43fd-8ba7-a1f2c06adb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute loss using MSE\n",
    "\n",
    "class MeanSquaredError:\n",
    "    @staticmethod\n",
    "    def apply(y_true: np.ndarray, y_pred: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Apply MSE loss\n",
    "        '''\n",
    "        return ((y_pred - y_true) ** 2) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f68519-7094-41a1-b6f4-3e0519b9096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Neuron Model\n",
    "\n",
    "class SNM:\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> 'SNM':\n",
    "        '''\n",
    "        Fit the model with training features and labels\n",
    "        Compute initial (random) weights and biases\n",
    "        '''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.sample_count = len(X)\n",
    "        if len(y) != self.sample_count:\n",
    "            raise ValueError(\n",
    "                \"Number of Samples is not equal to number of labels\"\n",
    "            )\n",
    "        if self.y.ndim == 1:\n",
    "            self.y = self.y.reshape((-1, 1))\n",
    "        \n",
    "        self.rng = np.random.default_rng()\n",
    "        self.weights = self.rng.normal(0, 1e-2, (X.shape[-1])).reshape((-1, 1))\n",
    "        self.bias = self.rng.normal(0, 0.01, 1)\n",
    "        return self\n",
    "    \n",
    "    def train(self, batch_size: int = 24, epochs: int = 3,\n",
    "              learning_rate:float = 1e-2, verbose: bool = False) -> None:\n",
    "        '''\n",
    "        Train the model with stochastic gradient descent\n",
    "        for given number of epochs and batch size\n",
    "        '''\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = min(batch_size, self.sample_count)\n",
    "        for epoch in range(epochs):\n",
    "            self._run_epoch()\n",
    "            loss = MeanSquaredError.apply(self.y, self.predict(self.X))\n",
    "            loss = np.sum(loss)\n",
    "            if verbose:\n",
    "                print(f'Epoch {epoch + 1}, {loss = }')\n",
    "                \n",
    "    def _run_epoch(self):\n",
    "        '''\n",
    "        Run all iterations for one epoch\n",
    "        '''\n",
    "        for X, y in self._batches():\n",
    "            self._run_batch(X, y)\n",
    "    \n",
    "    def _run_batch(self, X, y):\n",
    "        '''\n",
    "        Run an iteration using a minibatch\n",
    "        Update the weights and biases with SGD\n",
    "        '''\n",
    "        output = self.predict(X)\n",
    "        # e of the e * p hadamard product [e = z(k) - y(k)]\n",
    "        e = output - y\n",
    "        # p = 1 for linear activation\n",
    "        p = 1\n",
    "        self.weights -= (self.learning_rate / len(X)) * (X.T @ (e * p))\n",
    "        self.bias -= self.learning_rate\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict the output of this SNM\n",
    "        '''\n",
    "        return LinearRegression.apply(X, self.weights, self.bias)\n",
    "    \n",
    "    def _batches(self):\n",
    "        '''\n",
    "        Get random mini batches of training data\n",
    "        '''\n",
    "        indices = np.arange(self.sample_count)\n",
    "        self.rng.shuffle(indices)\n",
    "        for i in range(0, self.sample_count, self.batch_size):\n",
    "            idxs = indices[i : min(i + self.batch_size, self.sample_count)]\n",
    "            yield self.X[idxs], self.y[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2453e65b-f8c0-4913-9316-ce11dff09b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 0.2858774788256405\n",
      "Epoch 2, loss = 0.17275269518353448\n",
      "Epoch 3, loss = 0.13616822555695537\n",
      "Weights are = [0.12136325 0.00711381 0.20327476]\n",
      "Bias is = [-0.22644345]\n"
     ]
    }
   ],
   "source": [
    "filename = 'iris.csv'\n",
    "\n",
    "data = np.genfromtxt(filename, delimiter=',')\n",
    "X = data[:, :3]\n",
    "y = data[:, 3]\n",
    "\n",
    "snm = SNM()\n",
    "snm.fit(X, y)\n",
    "snm.train(verbose=True)\n",
    "\n",
    "print(f'Weights are = {snm.weights.flatten()}')\n",
    "print(f'Bias is = {snm.bias.flatten()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "494de1e0-ce5c-497c-823a-6a47d24445d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score = 76.463%\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y.flatten(), snm.predict(X).flatten())\n",
    "r2 = r2 * 100\n",
    "\n",
    "print(f'R2 Score = {r2:.3f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
